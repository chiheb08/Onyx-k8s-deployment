# File Upload UX & Performance - Deep Research & Recommendations

## ðŸ” Research: How Other Platforms Handle File Uploads

### 1. **ChatGPT (OpenAI)**

**File Upload Behavior:**
- âœ… **Input is disabled** while files are processing
- âœ… Shows **clear progress indicators** ("Processing document...")
- âœ… **Visual feedback** with file preview cards showing processing state
- âœ… **Blocks message submission** until files are ready
- âœ… Uses **optimistic UI** - files appear immediately but are marked as "processing"
- âœ… **Real-time status updates** without page refresh

**Performance Optimizations:**
- **Parallel processing** - Multiple files processed simultaneously
- **Progressive enhancement** - Small files work immediately, large files use retrieval
- **Smart chunking** - Documents split intelligently based on structure
- **Background indexing** - Processing happens asynchronously

**Key UX Patterns:**
```typescript
// ChatGPT's approach:
1. User uploads file â†’ File appears immediately with "Processing..." badge
2. Input field shows: "Please wait while we process your document"
3. Send button is disabled with tooltip: "Document is being processed"
4. Once ready â†’ Input enabled, send button active
5. Clear visual distinction between "uploading" and "processing"
```

---

### 2. **Claude (Anthropic)**

**File Upload Behavior:**
- âœ… **Input remains enabled** but shows warning message
- âœ… **Send button disabled** with explanation tooltip
- âœ… **Inline status messages** above input: "Processing 2 files... Please wait"
- âœ… **File cards show progress** with percentage or spinner
- âœ… **Graceful degradation** - Can type but can't send until ready

**Performance Optimizations:**
- **Streaming processing** - Shows progress as chunks are processed
- **Priority queuing** - Small files processed first
- **Smart retry** - Automatic retry on failures with exponential backoff
- **Batch optimization** - Groups similar files for efficient processing

**Key UX Patterns:**
```typescript
// Claude's approach:
1. User uploads file â†’ File card appears with spinner
2. Input shows placeholder: "Processing files... (2 remaining)"
3. Send button: disabled + tooltip "Wait for files to finish processing"
4. Can still type (for future messages) but can't send
5. Real-time countdown: "Processing... (1 remaining)"
```

---

### 3. **Perplexity**

**File Upload Behavior:**
- âœ… **Input completely disabled** during processing
- âœ… **Overlay message**: "Processing your documents. This may take a moment..."
- âœ… **Progress bar** showing overall progress
- âœ… **Estimated time remaining** for large files
- âœ… **Cancel option** for long-running uploads

**Performance Optimizations:**
- **Client-side preprocessing** - Extract text before upload
- **Compression** - Compress files before upload
- **Resumable uploads** - Can resume if connection drops
- **Smart batching** - Process files in optimal batches

**Key UX Patterns:**
```typescript
// Perplexity's approach:
1. User uploads file â†’ Upload progress bar appears
2. Input field: disabled + overlay "Processing documents..."
3. Progress indicator: "Processing 3/5 files (60%)"
4. Estimated time: "~30 seconds remaining"
5. Cancel button available for long operations
```

---

### 4. **Google Gemini**

**File Upload Behavior:**
- âœ… **Input enabled** but with visual warning
- âœ… **Send button disabled** with clear reason
- âœ… **File preview** with processing animation
- âœ… **Status badges** on each file card
- âœ… **Bulk operations** - Can upload multiple files efficiently

**Performance Optimizations:**
- **Incremental processing** - Files available as soon as first chunk is ready
- **Parallel workers** - Multiple files processed concurrently
- **Caching** - Previously processed files cached for instant access
- **Adaptive chunking** - Chunk size based on file type and size

---

## ðŸ“Š Comparison Table

| Platform | Input Disabled? | Send Disabled? | Progress Indicator | Status Updates | Performance Features |
|----------|----------------|----------------|-------------------|----------------|---------------------|
| **ChatGPT** | âœ… Yes | âœ… Yes | âœ… Spinner + Text | âœ… Real-time | Parallel processing, Smart chunking |
| **Claude** | âŒ No (can type) | âœ… Yes | âœ… Spinner + Count | âœ… Real-time | Streaming, Priority queue |
| **Perplexity** | âœ… Yes | âœ… Yes | âœ… Progress bar | âœ… Real-time | Client-side preprocess, Compression |
| **Google Gemini** | âŒ No (warning) | âœ… Yes | âœ… Animation | âœ… Real-time | Incremental, Parallel workers |
| **Onyx (Current)** | âŒ No | âš ï¸ Partial | âœ… File cards | âœ… Polling | Async processing, Polling |

---

## ðŸŽ¯ Best Practices Summary

### **UX Best Practices:**

1. **Clear Visual Feedback**
   - âœ… Show file cards immediately with processing state
   - âœ… Use spinners/animations for active processing
   - âœ… Display status text: "Processing...", "Uploading...", "Ready"
   - âœ… Color coding: Yellow (processing), Green (ready), Red (failed)

2. **Input State Management**
   - âœ… **Option A (Recommended)**: Disable input + show message
   - âœ… **Option B**: Enable input but disable send + show warning
   - âŒ **Never**: Allow sending while files are processing

3. **Progress Communication**
   - âœ… Show which files are processing
   - âœ… Display count: "Processing 2 of 5 files"
   - âœ… For large files: Show estimated time
   - âœ… Real-time status updates (no page refresh needed)

4. **Error Handling**
   - âœ… Clear error messages on file cards
   - âœ… Retry option for failed files
   - âœ… Don't block other files if one fails

---

## ðŸš€ Performance Optimization Recommendations

### **1. Frontend Optimizations**

#### **A. Reduce Polling Frequency**
**Current:** Polls every 3-10 seconds
**Recommended:** 
- Start with 2 seconds for first 30 seconds
- Increase to 5 seconds after 30 seconds
- Increase to 10 seconds after 2 minutes
- Stop polling when all files are completed

```typescript
// Adaptive polling strategy
const getPollInterval = (elapsedTime: number, fileCount: number) => {
  if (elapsedTime < 30000) return 2000;  // First 30s: 2s
  if (elapsedTime < 120000) return 5000;  // Next 90s: 5s
  return 10000;  // After 2min: 10s
};
```

#### **B. Batch Status Checks**
**Current:** Checks all files individually
**Recommended:** Batch API calls for multiple files

```typescript
// Instead of: await Promise.all(files.map(f => checkStatus(f.id)))
// Use: await checkBatchStatus(fileIds)
```

#### **C. Optimistic UI Updates**
**Current:** Waits for server response
**Recommended:** Update UI immediately, sync with server

```typescript
// Immediately show file as "UPLOADING" before server confirms
setCurrentMessageFiles(prev => [...prev, {
  ...file,
  status: UserFileStatus.UPLOADING  // Optimistic update
}]);
```

#### **D. Debounce Status Updates**
**Current:** Updates on every poll
**Recommended:** Only update if status actually changed

```typescript
// Only trigger re-render if status changed
const hasStatusChanged = (prev: ProjectFile[], next: ProjectFile[]) => {
  return prev.some((p, i) => p.status !== next[i]?.status);
};
```

---

### **2. Backend Optimizations**

#### **A. Streaming Status Updates**
**Current:** Polling (client asks server)
**Recommended:** Server-Sent Events (SSE) or WebSockets (server pushes to client)

```python
# Backend: Stream status updates
@app.get("/api/user/files/status/stream")
async def stream_file_statuses(file_ids: list[UUID]):
    async def event_generator():
        while True:
            statuses = get_file_statuses(file_ids)
            yield f"data: {json.dumps(statuses)}\n\n"
            await asyncio.sleep(2)  # Update every 2s
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

**Benefits:**
- âœ… Real-time updates (no polling delay)
- âœ… Reduced server load (no constant polling)
- âœ… Better user experience (instant feedback)

#### **B. Incremental Processing**
**Current:** File must be fully processed before use
**Recommended:** Make chunks available as soon as they're ready

```python
# Backend: Return partial results
def process_file_incrementally(file_id: UUID):
    chunks_ready = []
    for chunk in process_chunks(file_id):
        chunks_ready.append(chunk)
        # Update status: "Processing (50% complete)"
        update_file_status(file_id, {
            "status": "PROCESSING",
            "progress": len(chunks_ready) / total_chunks * 100
        })
        # Make available chunks searchable immediately
        index_chunks(chunks_ready)
```

#### **C. Priority Queue**
**Current:** Files processed in upload order
**Recommended:** Process small files first, then large files

```python
# Backend: Priority-based processing
def prioritize_files(files: list[File]) -> list[File]:
    return sorted(files, key=lambda f: (
        f.size,  # Small files first
        -f.priority if hasattr(f, 'priority') else 0
    ))
```

#### **D. Parallel Processing**
**Current:** Files processed sequentially
**Recommended:** Process multiple files concurrently (with limits)

```python
# Backend: Concurrent processing
async def process_files_parallel(files: list[File], max_concurrent: int = 3):
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_one(file: File):
        async with semaphore:
            return await process_file(file)
    
    return await asyncio.gather(*[process_one(f) for f in files])
```

---

### **3. Architecture Optimizations**

#### **A. Client-Side Preprocessing**
**Current:** All processing on server
**Recommended:** Extract text/metadata on client before upload

```typescript
// Frontend: Preprocess before upload
async function preprocessFile(file: File) {
  // Extract text on client (for small files)
  if (file.size < 5 * 1024 * 1024) {  // < 5MB
    const text = await extractText(file);
    return { file, preprocessedText: text };
  }
  return { file };
}
```

**Benefits:**
- âœ… Faster initial response (text ready immediately)
- âœ… Reduced server load
- âœ… Better error handling (catch issues early)

#### **B. Compression Before Upload**
**Current:** Upload files as-is
**Recommended:** Compress large files before upload

```typescript
// Frontend: Compress before upload
async function compressFile(file: File): Promise<File> {
  if (file.size > 10 * 1024 * 1024) {  // > 10MB
    // Use compression library (e.g., pako for gzip)
    const compressed = await compress(file);
    return new File([compressed], file.name, { type: file.type });
  }
  return file;
}
```

#### **C. Resumable Uploads**
**Current:** Restart on failure
**Recommended:** Resume from last chunk

```typescript
// Frontend: Resumable upload
async function uploadFileResumable(file: File) {
  const chunkSize = 5 * 1024 * 1024;  // 5MB chunks
  const totalChunks = Math.ceil(file.size / chunkSize);
  
  for (let i = 0; i < totalChunks; i++) {
    const chunk = file.slice(i * chunkSize, (i + 1) * chunkSize);
    await uploadChunk(chunk, i, totalChunks, file.id);
  }
}
```

---

## ðŸ“ Step-by-Step Implementation Plan

### **Phase 1: Disable Input While Files Processing (Immediate Fix)**

**Goal:** Prevent users from typing/sending while files are processing

**Steps:**

1. **Add processing state check**
2. **Disable textarea when files are processing**
3. **Disable send button when files are processing**
4. **Show clear message to user**

**Files to Modify:**
- `onyx-repo/web/src/app/chat/components/input/ChatInputBar.tsx`

---

### **Phase 2: Improve Status Updates (Short-term)**

**Goal:** Better real-time feedback

**Steps:**

1. **Implement adaptive polling** (2s â†’ 5s â†’ 10s)
2. **Add progress indicators** (X of Y files processed)
3. **Show estimated time** for large files
4. **Batch status API calls**

**Files to Modify:**
- `onyx-repo/web/src/app/chat/projects/ProjectsContext.tsx`
- `onyx-repo/web/src/app/chat/projects/projectsService.ts`

---

### **Phase 3: Backend Optimizations (Medium-term)**

**Goal:** Faster processing and better scalability

**Steps:**

1. **Implement SSE/WebSocket for status updates**
2. **Add incremental processing** (chunks available as ready)
3. **Implement priority queue** (small files first)
4. **Add parallel processing** (multiple files concurrently)

**Files to Modify:**
- `onyx-repo/backend/onyx/server/features/projects/api.py`
- `onyx-repo/backend/onyx/background/celery/tasks/user_file_processing/tasks.py`

---

### **Phase 4: Advanced Optimizations (Long-term)**

**Goal:** Best-in-class performance

**Steps:**

1. **Client-side preprocessing** (extract text before upload)
2. **Compression** (compress large files)
3. **Resumable uploads** (resume on failure)
4. **Smart caching** (cache processed files)

---

## ðŸŽ¨ UX Design Recommendations

### **Visual States:**

```typescript
// File Card States
enum FileCardState {
  UPLOADING = "uploading",      // Blue spinner, "Uploading..."
  PROCESSING = "processing",     // Yellow spinner, "Processing..."
  COMPLETED = "completed",       // Green checkmark, file name
  FAILED = "failed",            // Red X, "Failed - Retry?"
  CANCELED = "canceled"         // Gray, "Canceled"
}
```

### **Input States:**

```typescript
// Input States
enum InputState {
  READY = "ready",              // Normal input, can type and send
  PROCESSING = "processing",    // Disabled input, "Processing files..."
  UPLOADING = "uploading"       // Disabled input, "Uploading files..."
}
```

### **Message Examples:**

- âœ… **Good**: "Processing 2 files... Please wait"
- âœ… **Good**: "Files are being indexed. This may take a moment."
- âœ… **Good**: "3 of 5 files ready. ~30 seconds remaining"
- âŒ **Bad**: "Processing..." (too vague)
- âŒ **Bad**: "Please wait" (no context)

---

## ðŸ“ˆ Performance Metrics to Track

1. **Upload Time**: Time from file selection to "COMPLETED"
2. **Processing Time**: Time from upload complete to indexing complete
3. **Time to First Chunk**: Time until first chunk is searchable
4. **Polling Efficiency**: Number of polls per file completion
5. **User Wait Time**: Time user waits before they can send message

**Target Metrics:**
- Upload time: < 5s for files < 10MB
- Processing time: < 30s for files < 50MB
- Time to first chunk: < 10s
- Polling efficiency: < 10 polls per file
- User wait time: < 60s for typical files

---

## âœ… Implementation Priority

**High Priority (Do First):**
1. âœ… Disable input while files processing
2. âœ… Improve status messages
3. âœ… Adaptive polling

**Medium Priority (Do Next):**
4. âš ï¸ SSE/WebSocket status updates
5. âš ï¸ Incremental processing
6. âš ï¸ Priority queue

**Low Priority (Nice to Have):**
7. âšª Client-side preprocessing
8. âšª Compression
9. âšª Resumable uploads

---

This research provides a comprehensive foundation for improving Onyx's file upload UX and performance. The next step is implementing Phase 1 (disable input while processing) as an immediate fix.


