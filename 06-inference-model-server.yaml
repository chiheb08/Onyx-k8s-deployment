# ============================================================================
# Inference Model Server Deployment for Onyx
# ============================================================================
# AI/ML embeddings server for real-time query processing
# Image: onyxdotapp/onyx-model-server
# Port: 9000
# ============================================================================

---
apiVersion: v1
kind: Service
metadata:
  name: inference-model-server
  labels:
    app: inference-model-server
spec:
  type: ClusterIP
  ports:
    - name: modelserver
      port: 9000
      targetPort: 9000
      protocol: TCP
  selector:
    app: inference-model-server

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-model-server
  labels:
    app: inference-model-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: inference-model-server
  template:
    metadata:
      labels:
        app: inference-model-server
    spec:
      containers:
        - name: model-server
          image: onyxdotapp/onyx-model-server:nightly-20241004
          imagePullPolicy: IfNotPresent
          ports:
            - name: modelserver
              containerPort: 9000
              protocol: TCP
          command:
            - uvicorn
            - model_server.main:app
            - --host
            - "0.0.0.0"
            - --port
            - "9000"
          resources:
            requests:
              cpu: 500m          # Reduced from Helm (2000m) for minimal
              memory: 2Gi        # Reduced from Helm (6Gi) for minimal
            limits:
              cpu: 2000m         # Reduced from Helm (4000m)
              memory: 4Gi        # Reduced from Helm (10Gi)
          livenessProbe:
            httpGet:
              path: /health
              port: 9000
            initialDelaySeconds: 120
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: 9000
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          volumeMounts:
            - name: model-cache
              mountPath: /app/.cache/huggingface
      volumes:
        - name: model-cache
          emptyDir: {}  # Use emptyDir for minimal deployment (models download on start)
      restartPolicy: Always

